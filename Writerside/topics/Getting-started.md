# Getting started

This section is the “happy path” for getting the app running locally.

## Recommended path

1) Follow the quick setup: [Quickstart.md](Quickstart.md)
2) Configure environment variables as needed: [Configuration.md](Configuration.md)
3) If you want the reverse-proxy layout (Nginx), see: [Deployment.md](Deployment.md)

## Install without building (optional)

If you don’t want to clone/build the repo:

- Download and run a WAR from GitHub Releases: [Releases.md](Releases.md)
- Run the prebuilt GHCR images: [Container-images.md](Container-images.md)

## Data and AI

- Database backup, restore, and migrations: [Database.md](Database.md)
- AI setup (hosted or local llama.cpp): [AI-Integration.md](AI-Integration.md)
